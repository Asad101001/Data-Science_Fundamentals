{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "535a4ca0-b9d3-4dbd-9665-7abf7671058f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Household Size</th>\n",
       "      <th>Daily Usage Hours</th>\n",
       "      <th>Number of Appliances</th>\n",
       "      <th>Electricity Bill ($)</th>\n",
       "      <th>Income ($1000)</th>\n",
       "      <th>Credit Score</th>\n",
       "      <th>Loan Approved</th>\n",
       "      <th>Annual Income ($1000)</th>\n",
       "      <th>Spending Score</th>\n",
       "      <th>Age</th>\n",
       "      <th>Day of Year</th>\n",
       "      <th>Temperature (°C)</th>\n",
       "      <th>Rainfall (mm)</th>\n",
       "      <th>Storm Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>4.121932</td>\n",
       "      <td>18</td>\n",
       "      <td>147.340264</td>\n",
       "      <td>92</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>83.989762</td>\n",
       "      <td>3.618998</td>\n",
       "      <td>58</td>\n",
       "      <td>176</td>\n",
       "      <td>30.858175</td>\n",
       "      <td>92.324509</td>\n",
       "      <td>0.536609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>5.340987</td>\n",
       "      <td>8</td>\n",
       "      <td>102.298054</td>\n",
       "      <td>55</td>\n",
       "      <td>741</td>\n",
       "      <td>1</td>\n",
       "      <td>65.791359</td>\n",
       "      <td>10.741726</td>\n",
       "      <td>54</td>\n",
       "      <td>81</td>\n",
       "      <td>-1.514957</td>\n",
       "      <td>83.767306</td>\n",
       "      <td>0.433643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8.377547</td>\n",
       "      <td>11</td>\n",
       "      <td>74.933748</td>\n",
       "      <td>40</td>\n",
       "      <td>710</td>\n",
       "      <td>1</td>\n",
       "      <td>65.849038</td>\n",
       "      <td>46.313771</td>\n",
       "      <td>58</td>\n",
       "      <td>230</td>\n",
       "      <td>-1.748492</td>\n",
       "      <td>50.400873</td>\n",
       "      <td>0.059707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>4.741491</td>\n",
       "      <td>5</td>\n",
       "      <td>131.920011</td>\n",
       "      <td>39</td>\n",
       "      <td>730</td>\n",
       "      <td>1</td>\n",
       "      <td>60.660647</td>\n",
       "      <td>70.232468</td>\n",
       "      <td>69</td>\n",
       "      <td>168</td>\n",
       "      <td>-1.553685</td>\n",
       "      <td>62.423995</td>\n",
       "      <td>0.760063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.119485</td>\n",
       "      <td>7</td>\n",
       "      <td>101.182465</td>\n",
       "      <td>66</td>\n",
       "      <td>808</td>\n",
       "      <td>1</td>\n",
       "      <td>82.761512</td>\n",
       "      <td>75.185150</td>\n",
       "      <td>26</td>\n",
       "      <td>237</td>\n",
       "      <td>10.830722</td>\n",
       "      <td>182.110186</td>\n",
       "      <td>0.725904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Household Size  Daily Usage Hours  Number of Appliances  \\\n",
       "0               4           4.121932                    18   \n",
       "1               5           5.340987                     8   \n",
       "2               3           8.377547                    11   \n",
       "3               5           4.741491                     5   \n",
       "4               5           5.119485                     7   \n",
       "\n",
       "   Electricity Bill ($)  Income ($1000)  Credit Score  Loan Approved  \\\n",
       "0            147.340264              92           689              0   \n",
       "1            102.298054              55           741              1   \n",
       "2             74.933748              40           710              1   \n",
       "3            131.920011              39           730              1   \n",
       "4            101.182465              66           808              1   \n",
       "\n",
       "   Annual Income ($1000)  Spending Score  Age  Day of Year  Temperature (°C)  \\\n",
       "0              83.989762        3.618998   58          176         30.858175   \n",
       "1              65.791359       10.741726   54           81         -1.514957   \n",
       "2              65.849038       46.313771   58          230         -1.748492   \n",
       "3              60.660647       70.232468   69          168         -1.553685   \n",
       "4              82.761512       75.185150   26          237         10.830722   \n",
       "\n",
       "   Rainfall (mm)  Storm Probability  \n",
       "0      92.324509           0.536609  \n",
       "1      83.767306           0.433643  \n",
       "2      50.400873           0.059707  \n",
       "3      62.423995           0.760063  \n",
       "4     182.110186           0.725904  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"multi_model_dataset.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b17f34b1-aab5-4685-a34a-aa5ce8153e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dilib.DESKTOP-E7J5GDR\\New folder\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([-0.12548149,  0.01220213, -0.02528599]),\n",
       " 175.66844480680675,\n",
       " 62.79516677822829)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. Electricity Bill Prediction\n",
    "#Question: Predict the electricity bill amount based on household size, daily usage hours,and the number of appliances.\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Features and target selection\n",
    "features = ['Household Size', 'Daily Usage Hours', 'Number of Appliances']\n",
    "target = 'Electricity Bill ($)'\n",
    "\n",
    "# Extract features (X) and target (y)\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train a linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Return model coefficients and performance metrics\n",
    "model.coef_, model.intercept_, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "40f89d13-0a82-4283-a006-bfc63c2e2ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dilib.DESKTOP-E7J5GDR\\New folder\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\dilib.DESKTOP-E7J5GDR\\New folder\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "62.79288864135742"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model: Linear Regression or ANN with one output neuron.\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Scale the input features for ANN\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Build the ANN model\n",
    "ann_model = Sequential([\n",
    "    Dense(1, activation='relu', input_shape=(X_train_scaled.shape[1],)),  # Hidden layer with 16 neurons\n",
    "    Dense(1)  # Output layer with 1 neuron for predicting the bill\n",
    "])\n",
    "\n",
    "# Compile the ANN model\n",
    "ann_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train the ANN model\n",
    "history = ann_model.fit(X_train_scaled, y_train, epochs=25, verbose=0)\n",
    "\n",
    "# Evaluate the ANN model on test data\n",
    "ann_loss, ann_mae = ann_model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "\n",
    "# Predictions using ANN\n",
    "y_pred_ann = ann_model.predict(X_test_scaled, verbose=0) \n",
    "\n",
    "# Calculate RMSE and R2 for ANN\n",
    "ann_rmse = mean_squared_error(y_test, y_pred_ann, squared=False)\n",
    "ann_r2 = r2_score(y_test, y_pred_ann)\n",
    "\n",
    "# Return ANN metrics and compare them with Linear Regression\n",
    "ann_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8d49a8e4-b0b6-409b-846a-f40579074ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Mean Sqaured Error:\n",
      " 72.3769132566701\n",
      "Linear Regression R2:\n",
      " 8.226236789976582e-06\n",
      "ANN Mean Sqaured Error:\n",
      " 72.37501577537529\n",
      "ANN R2:\n",
      " 6.0658448325146e-05\n"
     ]
    }
   ],
   "source": [
    "#Evaluation: Use metrics like Mean Absolute Error (MAE) or R² score.\n",
    "\n",
    "print (\"Linear Regression Mean Sqaured Error:\\n\", rmse)\n",
    "print (\"Linear Regression R2:\\n\", r2)\n",
    "\n",
    "print (\"ANN Mean Sqaured Error:\\n\", ann_rmse)\n",
    "print (\"ANN R2:\\n\", ann_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "768eb048-2445-43bb-abec-2a71c8b98d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dilib.DESKTOP-E7J5GDR\\New folder\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9000/9000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 885us/step - loss: 183.1881 - mae: 11.5893 - val_loss: 169.8459 - val_mae: 11.2646\n",
      "Epoch 2/50\n",
      "\u001b[1m9000/9000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 844us/step - loss: 171.1962 - mae: 11.3485 - val_loss: 168.9035 - val_mae: 11.2348\n",
      "Epoch 3/50\n",
      "\u001b[1m9000/9000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 845us/step - loss: 169.9463 - mae: 11.3015 - val_loss: 168.8944 - val_mae: 11.2374\n",
      "Epoch 4/50\n",
      "\u001b[1m9000/9000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 842us/step - loss: 169.5703 - mae: 11.2871 - val_loss: 170.8885 - val_mae: 11.2934\n",
      "Epoch 5/50\n",
      "\u001b[1m9000/9000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 845us/step - loss: 168.9382 - mae: 11.2505 - val_loss: 168.8937 - val_mae: 11.2357\n",
      "Epoch 6/50\n",
      "\u001b[1m9000/9000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 842us/step - loss: 170.8070 - mae: 11.3324 - val_loss: 169.7513 - val_mae: 11.2488\n",
      "Epoch 7/50\n",
      "\u001b[1m9000/9000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 840us/step - loss: 169.7896 - mae: 11.2869 - val_loss: 168.9162 - val_mae: 11.2350\n",
      "Epoch 8/50\n",
      "\u001b[1m9000/9000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 838us/step - loss: 169.4121 - mae: 11.2719 - val_loss: 169.5920 - val_mae: 11.2467\n",
      "Epoch 9/50\n",
      "\u001b[1m9000/9000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 840us/step - loss: 168.9606 - mae: 11.2424 - val_loss: 168.9996 - val_mae: 11.2423\n",
      "Epoch 10/50\n",
      "\u001b[1m9000/9000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 824us/step - loss: 169.4488 - mae: 11.2838 - val_loss: 169.4291 - val_mae: 11.2510\n",
      "Epoch 11/50\n",
      "\u001b[1m9000/9000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 843us/step - loss: 170.9314 - mae: 11.3438 - val_loss: 168.9323 - val_mae: 11.2408\n",
      "Epoch 12/50\n",
      "\u001b[1m9000/9000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 831us/step - loss: 170.0774 - mae: 11.3035 - val_loss: 169.2414 - val_mae: 11.2458\n",
      "Epoch 13/50\n",
      "\u001b[1m9000/9000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 839us/step - loss: 170.6211 - mae: 11.3289 - val_loss: 170.4508 - val_mae: 11.2822\n",
      "Epoch 14/50\n",
      "\u001b[1m9000/9000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 846us/step - loss: 169.8051 - mae: 11.2916 - val_loss: 169.1772 - val_mae: 11.2498\n",
      "Epoch 15/50\n",
      "\u001b[1m9000/9000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 842us/step - loss: 169.9713 - mae: 11.3002 - val_loss: 169.3925 - val_mae: 11.2537\n",
      "Epoch 16/50\n",
      "\u001b[1m9000/9000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 842us/step - loss: 170.8138 - mae: 11.3290 - val_loss: 168.8398 - val_mae: 11.2303\n",
      "Epoch 17/50\n",
      "\u001b[1m9000/9000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 840us/step - loss: 168.5586 - mae: 11.2397 - val_loss: 168.7595 - val_mae: 11.2306\n",
      "Epoch 18/50\n",
      "\u001b[1m9000/9000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 836us/step - loss: 169.0715 - mae: 11.2618 - val_loss: 168.9677 - val_mae: 11.2403\n",
      "Epoch 19/50\n",
      "\u001b[1m9000/9000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 846us/step - loss: 170.1536 - mae: 11.2997 - val_loss: 168.8514 - val_mae: 11.2337\n",
      "Epoch 20/50\n",
      "\u001b[1m9000/9000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 851us/step - loss: 170.4539 - mae: 11.3187 - val_loss: 168.8413 - val_mae: 11.2346\n",
      "Epoch 21/50\n",
      "\u001b[1m9000/9000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 834us/step - loss: 169.3642 - mae: 11.2687 - val_loss: 168.8210 - val_mae: 11.2344\n",
      "Epoch 22/50\n",
      "\u001b[1m9000/9000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 841us/step - loss: 169.1821 - mae: 11.2655 - val_loss: 168.9113 - val_mae: 11.2400\n",
      "Epoch 23/50\n",
      "\u001b[1m9000/9000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 837us/step - loss: 169.6211 - mae: 11.2919 - val_loss: 169.0635 - val_mae: 11.2448\n",
      "Epoch 24/50\n",
      "\u001b[1m9000/9000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 845us/step - loss: 170.2642 - mae: 11.3077 - val_loss: 168.9893 - val_mae: 11.2300\n",
      "Epoch 25/50\n",
      "\u001b[1m9000/9000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 842us/step - loss: 169.9792 - mae: 11.2920 - val_loss: 168.9519 - val_mae: 11.2276\n",
      "Epoch 26/50\n",
      "\u001b[1m9000/9000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 860us/step - loss: 170.0328 - mae: 11.2901 - val_loss: 169.5650 - val_mae: 11.2580\n",
      "Epoch 27/50\n",
      "\u001b[1m9000/9000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 836us/step - loss: 170.6721 - mae: 11.3243 - val_loss: 168.7572 - val_mae: 11.2270\n",
      "Epoch 28/50\n",
      "\u001b[1m9000/9000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 847us/step - loss: 170.3350 - mae: 11.3174 - val_loss: 168.8569 - val_mae: 11.2374\n",
      "Epoch 29/50\n",
      "\u001b[1m9000/9000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 851us/step - loss: 170.2114 - mae: 11.3133 - val_loss: 168.7860 - val_mae: 11.2330\n",
      "Epoch 30/50\n",
      "\u001b[1m9000/9000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 849us/step - loss: 170.3927 - mae: 11.3099 - val_loss: 169.2799 - val_mae: 11.2503\n",
      "Epoch 31/50\n",
      "\u001b[1m9000/9000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 834us/step - loss: 170.1868 - mae: 11.3158 - val_loss: 168.7631 - val_mae: 11.2292\n",
      "Epoch 32/50\n",
      "\u001b[1m9000/9000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 845us/step - loss: 169.8105 - mae: 11.2923 - val_loss: 168.7687 - val_mae: 11.2312\n",
      "Epoch 33/50\n",
      "\u001b[1m9000/9000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 835us/step - loss: 170.0612 - mae: 11.3139 - val_loss: 168.8951 - val_mae: 11.2337\n",
      "Epoch 34/50\n",
      "\u001b[1m9000/9000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 845us/step - loss: 171.1620 - mae: 11.3422 - val_loss: 169.0333 - val_mae: 11.2430\n",
      "Epoch 35/50\n",
      "\u001b[1m9000/9000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 859us/step - loss: 169.0670 - mae: 11.2598 - val_loss: 169.4779 - val_mae: 11.2564\n",
      "Epoch 36/50\n",
      "\u001b[1m9000/9000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 845us/step - loss: 169.7255 - mae: 11.2817 - val_loss: 168.7729 - val_mae: 11.2247\n",
      "Epoch 37/50\n",
      "\u001b[1m9000/9000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 844us/step - loss: 169.4378 - mae: 11.2600 - val_loss: 168.8464 - val_mae: 11.2364\n",
      "Epoch 38/50\n",
      "\u001b[1m9000/9000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 846us/step - loss: 170.1150 - mae: 11.2975 - val_loss: 169.2599 - val_mae: 11.2506\n",
      "Epoch 39/50\n",
      "\u001b[1m9000/9000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 847us/step - loss: 169.6251 - mae: 11.2899 - val_loss: 169.1835 - val_mae: 11.2471\n",
      "Epoch 40/50\n",
      "\u001b[1m9000/9000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 849us/step - loss: 169.9775 - mae: 11.3066 - val_loss: 169.4923 - val_mae: 11.2555\n",
      "Epoch 41/50\n",
      "\u001b[1m9000/9000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 844us/step - loss: 169.6259 - mae: 11.2853 - val_loss: 168.8487 - val_mae: 11.2334\n",
      "Epoch 42/50\n",
      "\u001b[1m9000/9000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 843us/step - loss: 168.2971 - mae: 11.2262 - val_loss: 169.1206 - val_mae: 11.2460\n",
      "Epoch 43/50\n",
      "\u001b[1m9000/9000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 851us/step - loss: 170.6754 - mae: 11.3245 - val_loss: 168.7856 - val_mae: 11.2287\n",
      "Epoch 44/50\n",
      "\u001b[1m9000/9000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 854us/step - loss: 169.4208 - mae: 11.2709 - val_loss: 169.1282 - val_mae: 11.2472\n",
      "Epoch 45/50\n",
      "\u001b[1m9000/9000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 855us/step - loss: 171.1322 - mae: 11.3327 - val_loss: 168.8655 - val_mae: 11.2310\n",
      "Epoch 46/50\n",
      "\u001b[1m9000/9000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 835us/step - loss: 169.1007 - mae: 11.2717 - val_loss: 169.0962 - val_mae: 11.2431\n",
      "Epoch 47/50\n",
      "\u001b[1m9000/9000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 856us/step - loss: 169.4780 - mae: 11.2737 - val_loss: 168.8650 - val_mae: 11.2359\n",
      "Epoch 48/50\n",
      "\u001b[1m9000/9000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 847us/step - loss: 169.1961 - mae: 11.2896 - val_loss: 168.9372 - val_mae: 11.2407\n",
      "Epoch 49/50\n",
      "\u001b[1m9000/9000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 851us/step - loss: 170.1872 - mae: 11.3041 - val_loss: 168.9582 - val_mae: 11.2395\n",
      "Epoch 50/50\n",
      "\u001b[1m9000/9000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 851us/step - loss: 168.7895 - mae: 11.2375 - val_loss: 168.7266 - val_mae: 11.2310\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 760us/step - loss: 167.4995 - mae: 11.2379\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step\n",
      "Test MAE: 11.240429272697408\n",
      "Test RMSE: 12.965761764845317\n",
      "R² Score: -0.00010193264819946535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dilib.DESKTOP-E7J5GDR\\New folder\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Temperature Forecasting\n",
    "#Question: Predict the temperature based on the day of the year and rainfall.\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "# Select features and target\n",
    "X = df[['Day of Year', 'Rainfall (mm)']]\n",
    "y = df['Temperature (°C)']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Build the ANN model\n",
    "model = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_scaled.shape[1],)),  # Hidden layer with 32 neurons\n",
    "    Dense(16, activation='relu'),  # Second hidden layer\n",
    "    Dense(1)  # Output layer with 1 neuron for temperature prediction\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=8, validation_split=0.1, verbose=1)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_mae = model.evaluate(X_test_scaled, y_test, verbose=1)\n",
    "\n",
    "# Predict temperature\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Display results\n",
    "print(f\"Test MAE: {mae}\")\n",
    "print(f\"Test RMSE: {rmse}\")\n",
    "print(f\"R² Score: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a9007e84-583f-44b3-809a-a43ab796dd39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.47      0.48     10006\n",
      "           1       0.50      0.52      0.51      9994\n",
      "\n",
      "    accuracy                           0.50     20000\n",
      "   macro avg       0.50      0.50      0.50     20000\n",
      "weighted avg       0.50      0.50      0.50     20000\n",
      "\n",
      "\n",
      "Random Forest Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.50      0.50     10006\n",
      "           1       0.50      0.50      0.50      9994\n",
      "\n",
      "    accuracy                           0.50     20000\n",
      "   macro avg       0.50      0.50      0.50     20000\n",
      "weighted avg       0.50      0.50      0.50     20000\n",
      "\n",
      "\n",
      "ANN Results:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dilib.DESKTOP-E7J5GDR\\New folder\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.79      0.61     10006\n",
      "           1       0.49      0.20      0.29      9994\n",
      "\n",
      "    accuracy                           0.50     20000\n",
      "   macro avg       0.49      0.50      0.45     20000\n",
      "weighted avg       0.49      0.50      0.45     20000\n",
      "\n",
      "\n",
      "Model Performance Summary:\n",
      "Logistic Regression -> Accuracy: 0.50, Precision: 0.50, Recall: 0.52, F1-Score: 0.51\n",
      "Random Forest -> Accuracy: 0.50, Precision: 0.50, Recall: 0.50, F1-Score: 0.50\n",
      "ANN -> Accuracy: 0.50, Precision: 0.49, Recall: 0.20, F1-Score: 0.29\n"
     ]
    }
   ],
   "source": [
    "#Loan Approval Prediction\n",
    "#Question: Classify whether a loan application will be approved based on income and credit score.\n",
    "#Model: Logistic Regression, Random forest classifier, or ANN with a sigmoid activation function in the output layer.\n",
    "#Evaluation: Use accuracy, precision, recall, and F1-score.\n",
    "\n",
    "\n",
    " # Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Select features and target\n",
    "X = df[['Income ($1000)', 'Credit Score']]\n",
    "y = df['Loan Approved']  # Binary target: 0 or 1\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Function to evaluate model performance\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# 1. Logistic Regression\n",
    "print(\"Logistic Regression Results:\")\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "log_acc, log_prec, log_rec, log_f1 = evaluate_model(log_reg, X_test_scaled, y_test)\n",
    "\n",
    "# 2. Random Forest Classifier\n",
    "print(\"\\nRandom Forest Results:\")\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_clf.fit(X_train_scaled, y_train)\n",
    "rf_acc, rf_prec, rf_rec, rf_f1 = evaluate_model(rf_clf, X_test_scaled, y_test)\n",
    "\n",
    "# 3. ANN with Sigmoid Activation\n",
    "print(\"\\nANN Results:\")\n",
    "ann_model = Sequential([\n",
    "    Dense(16, activation='relu', input_shape=(X_train_scaled.shape[1],)),  # Hidden layer\n",
    "    Dense(8, activation='relu'),  # Second hidden layer\n",
    "    Dense(1, activation='sigmoid')  # Output layer with sigmoid activation\n",
    "])\n",
    "ann_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "ann_model.fit(X_train_scaled, y_train, epochs=50, batch_size=8, verbose=0)\n",
    "\n",
    "# Evaluate ANN\n",
    "y_pred_ann = (ann_model.predict(X_test_scaled) > 0.5).astype(int)\n",
    "ann_acc = accuracy_score(y_test, y_pred_ann)\n",
    "ann_prec = precision_score(y_test, y_pred_ann)\n",
    "ann_rec = recall_score(y_test, y_pred_ann)\n",
    "ann_f1 = f1_score(y_test, y_pred_ann)\n",
    "\n",
    "# Print ANN results\n",
    "print(classification_report(y_test, y_pred_ann))\n",
    "\n",
    "# Summary of Results\n",
    "print(\"\\nModel Performance Summary:\")\n",
    "print(f\"Logistic Regression -> Accuracy: {log_acc:.2f}, Precision: {log_prec:.2f}, Recall: {log_rec:.2f}, F1-Score: {log_f1:.2f}\")\n",
    "print(f\"Random Forest -> Accuracy: {rf_acc:.2f}, Precision: {rf_prec:.2f}, Recall: {rf_rec:.2f}, F1-Score: {rf_f1:.2f}\")\n",
    "print(f\"ANN -> Accuracy: {ann_acc:.2f}, Precision: {ann_prec:.2f}, Recall: {ann_rec:.2f}, F1-Score: {ann_f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a12c9bed-8ac8-4b6a-8b2e-f4f445d14779",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Storm Occurrence'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\New folder\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Storm Occurrence'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Select features and target\u001b[39;00m\n\u001b[0;32m     17\u001b[0m X \u001b[38;5;241m=\u001b[39m df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRainfall (mm)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStorm Probability\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m---> 18\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStorm Occurrence\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Binary target: 0 (No Storm) or 1 (Storm)\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Split the dataset into training and testing sets\u001b[39;00m\n\u001b[0;32m     21\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[1;32m~\\New folder\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\New folder\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Storm Occurrence'"
     ]
    }
   ],
   "source": [
    "#Storm Prediction\n",
    "#Question: Predict whether there will be a storm based on rainfall and storm probability.\n",
    "#Model: Random Forest or ANN. \n",
    "#Tip: Normalize features for better ANN performance.\n",
    "\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Select features and target\n",
    "X = df[['Rainfall (mm)', 'Storm Probability']]\n",
    "y = df['Storm Occurrence']  # Binary target: 0 (No Storm) or 1 (Storm)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize features for ANN\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Function to evaluate model performance\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# 1. Random Forest Classifier\n",
    "print(\"Random Forest Classifier Results:\")\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_acc, rf_prec, rf_rec, rf_f1 = evaluate_model(rf_model, X_test, y_test)\n",
    "\n",
    "# 2. ANN with Sigmoid Activation\n",
    "print(\"\\nArtificial Neural Network Results:\")\n",
    "ann_model = Sequential([\n",
    "    Dense(16, activation='relu', input_shape=(X_train_scaled.shape[1],)),  # Hidden layer with 16 neurons\n",
    "    Dense(8, activation='relu'),  # Second hidden layer\n",
    "    Dense(1, activation='sigmoid')  # Output layer with sigmoid activation\n",
    "])\n",
    "\n",
    "# Compile the ANN model\n",
    "ann_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the ANN model\n",
    "ann_model.fit(X_train_scaled, y_train, epochs=50, batch_size=8, verbose=1, validation_split=0.1)\n",
    "\n",
    "# Evaluate ANN\n",
    "y_pred_ann = (ann_model.predict(X_test_scaled) > 0.5).astype(int)\n",
    "ann_acc = accuracy_score(y_test, y_pred_ann)\n",
    "ann_prec = precision_score(y_test, y_pred_ann)\n",
    "ann_rec = recall_score(y_test, y_pred_ann)\n",
    "ann_f1 = f1_score(y_test, y_pred_ann)\n",
    "\n",
    "# Print ANN classification report\n",
    "print(classification_report(y_test, y_pred_ann))\n",
    "\n",
    "# Summary of Results\n",
    "print(\"\\nModel Performance Summary:\")\n",
    "print(f\"Random Forest -> Accuracy: {rf_acc:.2f}, Precision: {rf_prec:.2f}, Recall: {rf_rec:.2f}, F1-Score: {rf_f1:.2f}\")\n",
    "print(f\"ANN -> Accuracy: {ann_acc:.2f}, Precision: {ann_prec:.2f}, Recall: {ann_rec:.2f}, F1-Score: {ann_f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9ec05b-00d7-4801-a50d-7a84e234fafd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
