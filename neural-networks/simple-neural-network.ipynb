{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c204c37",
   "metadata": {},
   "source": [
    "# Build a simple Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b202e7b7",
   "metadata": {},
   "source": [
    "# Step 1: Understand Neural Networks"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3ee5f5b4",
   "metadata": {},
   "source": [
    "A neural network consists of:\n",
    "\n",
    "Input Layer: Takes in the data.\n",
    "Hidden Layers: Process the data with weights and biases.\n",
    "Output Layer: Produces the final prediction or classification.\n",
    "\n",
    "Each \"neuron\" performs:\n",
    "y=activation(wx+b)\n",
    "\n",
    "where:\n",
    "\n",
    "w: weight,\n",
    "x: input,\n",
    "b: bias,\n",
    "activation\n",
    "activation: a non-linear function (e.g., ReLU or Sigmoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dfb389",
   "metadata": {},
   "source": [
    "# Step 2: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a72fd4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in d:\\python\\lib\\site-packages (2.15.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in d:\\python\\lib\\site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in d:\\python\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in d:\\python\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in d:\\python\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in d:\\python\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in d:\\python\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in d:\\python\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in d:\\python\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in d:\\python\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in d:\\python\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in d:\\python\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in d:\\python\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in d:\\python\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.23.4)\n",
      "Requirement already satisfied: setuptools in d:\\python\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\python\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in d:\\python\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\python\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in d:\\python\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in d:\\python\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in d:\\python\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.60.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in d:\\python\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in d:\\python\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in d:\\python\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\python\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in d:\\python\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.26.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in d:\\python\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\python\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\python\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in d:\\python\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\python\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\python\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\python\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\python\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in d:\\python\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\python\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\python\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\python\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\python\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in d:\\python\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in d:\\python\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\python\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51e88e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\python\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c81ba8",
   "metadata": {},
   "source": [
    "# Step 3: Prepare the Data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0654582e",
   "metadata": {},
   "source": [
    "# Let’s create a simple dataset. For example, predicting the sum of two numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "718c1177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data (inputs and outputs)\n",
    "X_train=np.array([[1, 2], [2, 3], [3, 4], [4, 5]], dtype=float) # Inputs\n",
    "y_train=np.array([3, 5, 7, 9], dtype=float)  # Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e6ce5b",
   "metadata": {},
   "source": [
    "# Step 4: Build the Neural Network"
   ]
  },
  {
   "cell_type": "raw",
   "id": "df0af227",
   "metadata": {},
   "source": [
    "We’ll create a simple network with:\n",
    "\n",
    "2 input features,\n",
    "1 hidden layer (10 neurons),\n",
    "1 output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "426825fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\python\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(10, input_shape=(2,), activation='relu'),  # Hidden layer\n",
    "    Dense(1)                                         # Output layer\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d115fe2",
   "metadata": {},
   "source": [
    "# Step 5: Compile the Model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "12e0afef",
   "metadata": {},
   "source": [
    "The compilation step defines:\n",
    "\n",
    "Loss function: Measures error (e.g., MSE for regression).\n",
    "Optimizer: Updates weights (e.g., SGD or Adam).\n",
    "Metrics: Monitors performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9bd9375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\python\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss='mean_squared_error',metrics=['mae'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e766b0",
   "metadata": {},
   "source": [
    "# Step 6: Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca559495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From D:\\python\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\python\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1/1 [==============================] - 5s 5s/step - loss: 30.9730 - mae: 5.2101\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 30.7211 - mae: 5.1885\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 30.4701 - mae: 5.1670\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 30.2201 - mae: 5.1454\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 29.9709 - mae: 5.1238\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 29.7227 - mae: 5.1022\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 29.4754 - mae: 5.0807\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 29.2292 - mae: 5.0591\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 28.9839 - mae: 5.0375\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 28.7396 - mae: 5.0159\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 28.4963 - mae: 4.9942\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 28.2540 - mae: 4.9726\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 28.0128 - mae: 4.9510\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 27.7727 - mae: 4.9294\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 27.5336 - mae: 4.9078\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 27.2955 - mae: 4.8862\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 27.0586 - mae: 4.8646\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 26.8227 - mae: 4.8431\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 26.5880 - mae: 4.8215\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 26.3544 - mae: 4.7999\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 26.1218 - mae: 4.7783\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 25.8905 - mae: 4.7568\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 25.6602 - mae: 4.7352\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 25.4311 - mae: 4.7137\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 25.2031 - mae: 4.6922\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 24.9762 - mae: 4.6706\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 24.7505 - mae: 4.6491\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 24.5260 - mae: 4.6276\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 24.3026 - mae: 4.6062\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 24.0804 - mae: 4.5847\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.8593 - mae: 4.5632\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 23.6394 - mae: 4.5418\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.4206 - mae: 4.5204\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23.2031 - mae: 4.4990\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 22.9866 - mae: 4.4776\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.7714 - mae: 4.4562\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 22.5572 - mae: 4.4348\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.3443 - mae: 4.4134\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.1325 - mae: 4.3921\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 21.9219 - mae: 4.3708\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 21.7124 - mae: 4.3495\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 21.5041 - mae: 4.3282\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 21.2969 - mae: 4.3069\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 21.0909 - mae: 4.2856\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 20.8860 - mae: 4.2644\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 20.6822 - mae: 4.2431\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 20.4796 - mae: 4.2219\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 20.2781 - mae: 4.2007\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 20.0778 - mae: 4.1795\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 19.8786 - mae: 4.1583\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 19.6805 - mae: 4.1372\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 19.4835 - mae: 4.1160\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 19.2877 - mae: 4.0949\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 19.0929 - mae: 4.0737\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 18.8993 - mae: 4.0526\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 18.7068 - mae: 4.0315\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 18.5153 - mae: 4.0104\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 18.3250 - mae: 3.9894\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 18.1358 - mae: 3.9683\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 17.9476 - mae: 3.9472\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 17.7606 - mae: 3.9262\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 17.5746 - mae: 3.9052\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 17.3897 - mae: 3.8842\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 17.2059 - mae: 3.8631\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 17.0231 - mae: 3.8421\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 16.8415 - mae: 3.8212\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 16.6608 - mae: 3.8002\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 16.4813 - mae: 3.7792\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 16.3028 - mae: 3.7583\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 16.1253 - mae: 3.7373\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 15.9490 - mae: 3.7164\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 15.7736 - mae: 3.6955\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 15.5993 - mae: 3.6745\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 15.4261 - mae: 3.6536\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 15.2539 - mae: 3.6327\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 15.0828 - mae: 3.6118\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 14.9126 - mae: 3.5910\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 14.7436 - mae: 3.5701\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 14.5755 - mae: 3.5492\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 14.4085 - mae: 3.5284\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 14.2425 - mae: 3.5075\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 14.0776 - mae: 3.4867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.9137 - mae: 3.4658\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.7508 - mae: 3.4450\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 13.5890 - mae: 3.4242\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 13.4281 - mae: 3.4034\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 13.2684 - mae: 3.3826\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.1096 - mae: 3.3618\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 12.9519 - mae: 3.3410\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 12.7952 - mae: 3.3203\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 12.6395 - mae: 3.2995\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 12.4848 - mae: 3.2788\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 12.3312 - mae: 3.2580\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 12.1786 - mae: 3.2373\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 12.0271 - mae: 3.2166\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 11.8765 - mae: 3.1959\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 11.7271 - mae: 3.1752\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 11.5786 - mae: 3.1545\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 11.4312 - mae: 3.1338\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 11.2848 - mae: 3.1132\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x26cdd72fed0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model on your data:\n",
    "model.fit(X_train, y_train, epochs=100, verbose=1)\n",
    "# epochs: Number of iterations over the dataset.\n",
    "# verbose: Shows progress during training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a822790",
   "metadata": {},
   "source": [
    "# Step 7: Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e3d27f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "Predicted output: [[5.1006293]]\n"
     ]
    }
   ],
   "source": [
    "# Use the model to predict new data:\n",
    "X_test = np.array([[5, 6]], dtype=float)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Predicted output:\", y_pred)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2074ba45",
   "metadata": {},
   "source": [
    "The prediction result of 5.10 is because the model has learned from your training data, but it is not perfect due to several factors such as:\n",
    "\n",
    "Training Data is Limited Your training data only has 4 samples\n",
    "This is a very small dataset, so the model doesn't generalize well to unseen data like [5, 6].\n",
    "\n",
    "Lack of Precision in Training\n",
    "With only 100 epochs, the model hasn't fully converged to the optimal solution. Increasing the training duration or adding more data can improve accuracy."
   ]
  },
  {
   "cell_type": "raw",
   "id": "6629af72",
   "metadata": {},
   "source": [
    "# How to Improve Accuracy\n",
    "# Increase Training Data: Add more samples that cover a wider range of inputs.\n",
    "# Train for More Epochs: Increase training iterations to improve learning:\n",
    "# Normalize the Input Data: Neural networks perform better when inputs are normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c81abc6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 21.4450 - mae: 4.2153\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 21.1612 - mae: 4.1866\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 20.8628 - mae: 4.1563\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 20.5522 - mae: 4.1245\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 20.2314 - mae: 4.0914\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 19.9024 - mae: 4.0572\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 19.5668 - mae: 4.0220\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 19.2260 - mae: 3.9860\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 18.8813 - mae: 3.9493\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 18.5339 - mae: 3.9119\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 18.1848 - mae: 3.8740\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 17.8349 - mae: 3.8356\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 17.4849 - mae: 3.7969\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 17.1355 - mae: 3.7578\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 16.7874 - mae: 3.7185\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.4411 - mae: 3.6789\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.0969 - mae: 3.6392\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 15.7555 - mae: 3.5994\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 15.4170 - mae: 3.5595\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 15.0818 - mae: 3.5196\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 14.7501 - mae: 3.4796\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 14.4223 - mae: 3.4397\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 14.0985 - mae: 3.3997\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.7788 - mae: 3.3599\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.4634 - mae: 3.3201\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.1524 - mae: 3.2804\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 12.8459 - mae: 3.2409\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 12.5441 - mae: 3.2014\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 12.2468 - mae: 3.1621\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 11.9543 - mae: 3.1230\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 11.6665 - mae: 3.0840\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 11.3835 - mae: 3.0452\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 11.1053 - mae: 3.0065\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.8319 - mae: 2.9681\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 10.5633 - mae: 2.9298\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.2994 - mae: 2.8918\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.0403 - mae: 2.8539\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.7860 - mae: 2.8163\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.5364 - mae: 2.7789\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.2915 - mae: 2.7417\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.0513 - mae: 2.7047\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.8157 - mae: 2.6680\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.5847 - mae: 2.6315\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.3583 - mae: 2.5952\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.1363 - mae: 2.5592\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.9189 - mae: 2.5234\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.7059 - mae: 2.4879\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.4972 - mae: 2.4526\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.2929 - mae: 2.4176\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.0929 - mae: 2.3828\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.8971 - mae: 2.3483\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.7055 - mae: 2.3140\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.5180 - mae: 2.2800\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.3346 - mae: 2.2462\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.1552 - mae: 2.2127\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.9797 - mae: 2.1795\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.8082 - mae: 2.1465\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.6406 - mae: 2.1138\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.4768 - mae: 2.0813\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.3167 - mae: 2.0492\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.1603 - mae: 2.0173\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.0076 - mae: 1.9856\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.8584 - mae: 1.9542\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.7128 - mae: 1.9231\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.5707 - mae: 1.8923\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.4320 - mae: 1.8618\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.2966 - mae: 1.8315\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.1646 - mae: 1.8015\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.0359 - mae: 1.7717\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.9104 - mae: 1.7423\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7880 - mae: 1.7131\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.6687 - mae: 1.6842\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.5525 - mae: 1.6555\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.4393 - mae: 1.6272\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.3290 - mae: 1.5991\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.2216 - mae: 1.5713\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.1171 - mae: 1.5438\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.0154 - mae: 1.5166\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.9164 - mae: 1.4896\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.8200 - mae: 1.4630\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.7264 - mae: 1.4366\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.6353 - mae: 1.4105\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.5467 - mae: 1.3846\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.4606 - mae: 1.3591\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.3770 - mae: 1.3338\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.2957 - mae: 1.3088\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.2168 - mae: 1.2841\n",
      "Epoch 88/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step - loss: 2.1402 - mae: 1.2597\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.0658 - mae: 1.2356\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.9936 - mae: 1.2117\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.9235 - mae: 1.1882\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.8555 - mae: 1.1649\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7896 - mae: 1.1419\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7257 - mae: 1.1191\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.6638 - mae: 1.0967\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.6038 - mae: 1.0745\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5457 - mae: 1.0526\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4893 - mae: 1.0310\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4348 - mae: 1.0097\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.3820 - mae: 0.9886\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3309 - mae: 0.9678\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2815 - mae: 0.9473\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2337 - mae: 0.9271\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.1875 - mae: 0.9072\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1428 - mae: 0.8875\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0996 - mae: 0.8681\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.0578 - mae: 0.8493\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0175 - mae: 0.8331\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9786 - mae: 0.8171\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9410 - mae: 0.8013\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9047 - mae: 0.7857\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8697 - mae: 0.7704\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8359 - mae: 0.7554\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8034 - mae: 0.7405\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7720 - mae: 0.7259\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7417 - mae: 0.7115\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7126 - mae: 0.6973\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6845 - mae: 0.6833\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6574 - mae: 0.6696\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6314 - mae: 0.6561\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6063 - mae: 0.6427\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5822 - mae: 0.6297\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5590 - mae: 0.6168\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5366 - mae: 0.6041\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5152 - mae: 0.5917\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4946 - mae: 0.5794\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4747 - mae: 0.5674\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4557 - mae: 0.5556\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4374 - mae: 0.5439\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4199 - mae: 0.5325\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4030 - mae: 0.5213\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3869 - mae: 0.5103\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3714 - mae: 0.4995\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3565 - mae: 0.4888\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3422 - mae: 0.4784\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3286 - mae: 0.4682\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3155 - mae: 0.4581\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3029 - mae: 0.4482\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2909 - mae: 0.4386\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2794 - mae: 0.4291\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2684 - mae: 0.4198\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2579 - mae: 0.4106\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2478 - mae: 0.4017\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2382 - mae: 0.3947\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2290 - mae: 0.3883\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2202 - mae: 0.3820\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2118 - mae: 0.3758\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2038 - mae: 0.3697\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1961 - mae: 0.3638\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1888 - mae: 0.3579\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1818 - mae: 0.3522\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1751 - mae: 0.3466\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1688 - mae: 0.3412\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1627 - mae: 0.3358\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1569 - mae: 0.3306\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1514 - mae: 0.3254\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1461 - mae: 0.3204\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1411 - mae: 0.3155\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1364 - mae: 0.3107\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1318 - mae: 0.3060\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1275 - mae: 0.3014\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1234 - mae: 0.2969\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1195 - mae: 0.2925\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1158 - mae: 0.2882\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1123 - mae: 0.2840\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1089 - mae: 0.2799\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1057 - mae: 0.2759\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1027 - mae: 0.2720\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0998 - mae: 0.2682\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0971 - mae: 0.2644\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0945 - mae: 0.2608\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0920 - mae: 0.2572\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0897 - mae: 0.2537\n",
      "Epoch 174/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0874 - mae: 0.2503\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0853 - mae: 0.2470\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0833 - mae: 0.2438\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0814 - mae: 0.2406\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0797 - mae: 0.2387\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0780 - mae: 0.2370\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0763 - mae: 0.2354\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0748 - mae: 0.2338\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0734 - mae: 0.2323\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0720 - mae: 0.2308\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0707 - mae: 0.2294\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0695 - mae: 0.2279\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0683 - mae: 0.2266\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0672 - mae: 0.2252\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0662 - mae: 0.2239\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0652 - mae: 0.2226\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0643 - mae: 0.2214\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0634 - mae: 0.2201\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0626 - mae: 0.2189\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0618 - mae: 0.2178\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0611 - mae: 0.2167\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0604 - mae: 0.2156\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0597 - mae: 0.2145\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0591 - mae: 0.2135\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0585 - mae: 0.2124\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0580 - mae: 0.2115\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0574 - mae: 0.2105\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0569 - mae: 0.2096\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0565 - mae: 0.2087\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0560 - mae: 0.2078\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0556 - mae: 0.2069\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0552 - mae: 0.2061\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0549 - mae: 0.2052\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0545 - mae: 0.2045\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0542 - mae: 0.2037\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0539 - mae: 0.2029\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0536 - mae: 0.2022\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0533 - mae: 0.2015\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0530 - mae: 0.2008\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0528 - mae: 0.2001\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0526 - mae: 0.1995\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0523 - mae: 0.1988\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0521 - mae: 0.1982\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0519 - mae: 0.1976\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0518 - mae: 0.1970\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0516 - mae: 0.1965\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0514 - mae: 0.1959\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0513 - mae: 0.1954\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0511 - mae: 0.1948\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0510 - mae: 0.1943\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0508 - mae: 0.1938\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0507 - mae: 0.1934\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0506 - mae: 0.1929\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0505 - mae: 0.1924\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0504 - mae: 0.1920\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0503 - mae: 0.1916\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0502 - mae: 0.1912\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0501 - mae: 0.1908\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0500 - mae: 0.1904\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0499 - mae: 0.1900\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0498 - mae: 0.1896\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0497 - mae: 0.1893\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0497 - mae: 0.1889\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0496 - mae: 0.1886\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0495 - mae: 0.1882\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0495 - mae: 0.1879\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0494 - mae: 0.1876\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0493 - mae: 0.1873\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0493 - mae: 0.1872\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0492 - mae: 0.1872\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0492 - mae: 0.1871\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0491 - mae: 0.1871\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0491 - mae: 0.1870\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0490 - mae: 0.1870\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0490 - mae: 0.1870\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0489 - mae: 0.1869\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0489 - mae: 0.1869\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0489 - mae: 0.1869\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0488 - mae: 0.1868\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0488 - mae: 0.1868\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0487 - mae: 0.1867\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0487 - mae: 0.1867\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0487 - mae: 0.1867\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0486 - mae: 0.1866\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0486 - mae: 0.1866\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0485 - mae: 0.1865\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0485 - mae: 0.1865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0485 - mae: 0.1865\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0484 - mae: 0.1864\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0484 - mae: 0.1864\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0484 - mae: 0.1863\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0483 - mae: 0.1863\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0483 - mae: 0.1862\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0483 - mae: 0.1862\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0482 - mae: 0.1861\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0482 - mae: 0.1861\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0482 - mae: 0.1860\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0482 - mae: 0.1860\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0481 - mae: 0.1860\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0481 - mae: 0.1859\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0481 - mae: 0.1859\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0480 - mae: 0.1858\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0480 - mae: 0.1858\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0480 - mae: 0.1857\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0479 - mae: 0.1857\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0479 - mae: 0.1856\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0479 - mae: 0.1856\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0479 - mae: 0.1855\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0478 - mae: 0.1855\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0478 - mae: 0.1854\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0478 - mae: 0.1854\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0477 - mae: 0.1853\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0477 - mae: 0.1853\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0477 - mae: 0.1852\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0477 - mae: 0.1852\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0476 - mae: 0.1851\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0476 - mae: 0.1851\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0476 - mae: 0.1850\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0475 - mae: 0.1850\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0475 - mae: 0.1849\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0475 - mae: 0.1849\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0475 - mae: 0.1848\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0474 - mae: 0.1848\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0474 - mae: 0.1847\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0474 - mae: 0.1847\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0473 - mae: 0.1846\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0473 - mae: 0.1845\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0473 - mae: 0.1845\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0473 - mae: 0.1844\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0472 - mae: 0.1844\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0472 - mae: 0.1843\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0472 - mae: 0.1843\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0471 - mae: 0.1842\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0471 - mae: 0.1842\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0471 - mae: 0.1841\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0471 - mae: 0.1841\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0470 - mae: 0.1840\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0470 - mae: 0.1840\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0470 - mae: 0.1839\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0469 - mae: 0.1838\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0469 - mae: 0.1838\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0469 - mae: 0.1837\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0469 - mae: 0.1837\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0468 - mae: 0.1836\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0468 - mae: 0.1836\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0468 - mae: 0.1835\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0467 - mae: 0.1835\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0467 - mae: 0.1834\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0467 - mae: 0.1834\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0467 - mae: 0.1833\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0466 - mae: 0.1832\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0466 - mae: 0.1832\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0466 - mae: 0.1831\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0465 - mae: 0.1831\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0465 - mae: 0.1830\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0465 - mae: 0.1830\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0465 - mae: 0.1829\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0464 - mae: 0.1828\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0464 - mae: 0.1828\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0464 - mae: 0.1827\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0463 - mae: 0.1827\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0463 - mae: 0.1826\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0463 - mae: 0.1826\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0463 - mae: 0.1825\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0462 - mae: 0.1825\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0462 - mae: 0.1824\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0462 - mae: 0.1823\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0461 - mae: 0.1823\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0461 - mae: 0.1822\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0461 - mae: 0.1822\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0461 - mae: 0.1821\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0460 - mae: 0.1820\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0460 - mae: 0.1820\n",
      "Epoch 347/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0460 - mae: 0.1819\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0459 - mae: 0.1819\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0459 - mae: 0.1818\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0459 - mae: 0.1818\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0458 - mae: 0.1817\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0458 - mae: 0.1816\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0458 - mae: 0.1816\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0458 - mae: 0.1815\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0457 - mae: 0.1815\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0457 - mae: 0.1814\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0457 - mae: 0.1814\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0456 - mae: 0.1813\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0456 - mae: 0.1812\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0456 - mae: 0.1812\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0456 - mae: 0.1811\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0455 - mae: 0.1811\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0455 - mae: 0.1810\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0455 - mae: 0.1809\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0454 - mae: 0.1809\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0454 - mae: 0.1808\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0454 - mae: 0.1808\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0453 - mae: 0.1807\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0453 - mae: 0.1806\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0453 - mae: 0.1806\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0453 - mae: 0.1805\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0452 - mae: 0.1805\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0452 - mae: 0.1804\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0452 - mae: 0.1804\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0451 - mae: 0.1803\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0451 - mae: 0.1802\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0451 - mae: 0.1802\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0450 - mae: 0.1801\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0450 - mae: 0.1801\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0450 - mae: 0.1800\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0450 - mae: 0.1799\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0449 - mae: 0.1799\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0449 - mae: 0.1798\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0449 - mae: 0.1798\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0448 - mae: 0.1797\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0448 - mae: 0.1796\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0448 - mae: 0.1796\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0447 - mae: 0.1795\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0447 - mae: 0.1795\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0447 - mae: 0.1794\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0447 - mae: 0.1793\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0446 - mae: 0.1793\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0446 - mae: 0.1792\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0446 - mae: 0.1791\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0445 - mae: 0.1791\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0445 - mae: 0.1790\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0445 - mae: 0.1790\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0444 - mae: 0.1789\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0444 - mae: 0.1788\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0444 - mae: 0.1788\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0444 - mae: 0.1787\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0443 - mae: 0.1787\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0443 - mae: 0.1786\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0443 - mae: 0.1785\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0442 - mae: 0.1785\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0442 - mae: 0.1784\n",
      "Epoch 407/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0442 - mae: 0.1784\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0441 - mae: 0.1783\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0441 - mae: 0.1782\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0441 - mae: 0.1782\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0441 - mae: 0.1781\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0440 - mae: 0.1780\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0440 - mae: 0.1780\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0440 - mae: 0.1779\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0439 - mae: 0.1779\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0439 - mae: 0.1778\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0439 - mae: 0.1777\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0438 - mae: 0.1777\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0438 - mae: 0.1776\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0438 - mae: 0.1775\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0437 - mae: 0.1775\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0437 - mae: 0.1774\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0437 - mae: 0.1774\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0437 - mae: 0.1773\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0436 - mae: 0.1772\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0436 - mae: 0.1772\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0436 - mae: 0.1771\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0435 - mae: 0.1770\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0435 - mae: 0.1770\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0435 - mae: 0.1769\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0434 - mae: 0.1769\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0434 - mae: 0.1768\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0434 - mae: 0.1767\n",
      "Epoch 434/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0433 - mae: 0.1767\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0433 - mae: 0.1766\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0433 - mae: 0.1765\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0433 - mae: 0.1765\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0432 - mae: 0.1764\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0432 - mae: 0.1764\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0432 - mae: 0.1763\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0431 - mae: 0.1762\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0431 - mae: 0.1762\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0431 - mae: 0.1761\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0430 - mae: 0.1760\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0430 - mae: 0.1760\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0430 - mae: 0.1759\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0429 - mae: 0.1758\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0429 - mae: 0.1758\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0429 - mae: 0.1757\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0428 - mae: 0.1757\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0428 - mae: 0.1756\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0428 - mae: 0.1755\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0428 - mae: 0.1755\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0427 - mae: 0.1754\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0427 - mae: 0.1753\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0427 - mae: 0.1753\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0426 - mae: 0.1752\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0426 - mae: 0.1751\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0426 - mae: 0.1751\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0425 - mae: 0.1750\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0425 - mae: 0.1749\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0425 - mae: 0.1749\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0424 - mae: 0.1748\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0424 - mae: 0.1748\n",
      "Epoch 465/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0424 - mae: 0.1747\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0423 - mae: 0.1746\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0423 - mae: 0.1746\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0423 - mae: 0.1745\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0423 - mae: 0.1744\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0422 - mae: 0.1744\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0422 - mae: 0.1743\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0422 - mae: 0.1742\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0421 - mae: 0.1742\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0421 - mae: 0.1741\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0421 - mae: 0.1740\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0420 - mae: 0.1740\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0420 - mae: 0.1739\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0420 - mae: 0.1738\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0419 - mae: 0.1738\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0419 - mae: 0.1737\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0419 - mae: 0.1736\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0418 - mae: 0.1736\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0418 - mae: 0.1735\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0418 - mae: 0.1735\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0417 - mae: 0.1734\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0417 - mae: 0.1733\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0417 - mae: 0.1733\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0417 - mae: 0.1732\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0416 - mae: 0.1731\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0416 - mae: 0.1731\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0416 - mae: 0.1730\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0415 - mae: 0.1729\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0415 - mae: 0.1729\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0415 - mae: 0.1728\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0414 - mae: 0.1727\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0414 - mae: 0.1727\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0414 - mae: 0.1726\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0413 - mae: 0.1725\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0413 - mae: 0.1725\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0413 - mae: 0.1724\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Predicted output: [[10.908941]]\n"
     ]
    }
   ],
   "source": [
    "# Extended training data\n",
    "X_train = np.array([[1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7]], \n",
    "                   dtype=float)\n",
    "y_train = np.array([3, 5, 7, 9, 11, 13], dtype=float)\n",
    "\n",
    "# Re-train the model\n",
    "model.fit(X_train, y_train, epochs=500, verbose=1)\n",
    "\n",
    "# Predict again\n",
    "X_test = np.array([[5, 6]], dtype=float)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Predicted output:\", y_pred)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dcb320d7",
   "metadata": {},
   "source": [
    "Key Concepts Explained.\n",
    "\n",
    "Sequential Model: Layers are added in sequence.\n",
    "Activation Function: Non-linear transformations (e.g., ReLU) help the network learn complex patterns.\n",
    "Loss Function: Guides the model by showing how far predictions are from actual values.\n",
    "Optimizer: Adjusts weights to minimize loss."
   ]
  },
  {
   "cell_type": "raw",
   "id": "75508429",
   "metadata": {},
   "source": [
    "What’s Next?\n",
    "Experiment with more data.\n",
    "Add more layers or neurons.\n",
    "Try different activation functions and optimizers.\n",
    "Explore classification tasks (e.g., predicting categories)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17182cf",
   "metadata": {},
   "source": [
    "# Example : Simple ANN to Predict a Linear Relationship"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea02131",
   "metadata": {},
   "source": [
    "# Step 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b99a9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We’ll train an ANN to learn this simple linear relationship.\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d07e6382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training data\n",
    "X_train =np.array([[1], [2], [3], [4], [5]],dtype=float) # Input: x\n",
    "y_train =np.array([[3], [5], [7], [9], [11]],\n",
    "                  dtype=float) # Output: y = 2x + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c4f494c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ANN model\n",
    "model = Sequential([\n",
    "    Dense(1, input_shape=(1,), activation='linear') \n",
    "    # Simple ANN with one neuron\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03de11f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d34b2b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x26ce00a1390>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63a56398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 420ms/step\n",
      "Predicted outputs: [[-5.21194  ]\n",
      " [-6.0971484]]\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "X_test = np.array([[6], [7]], dtype=float)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Predicted outputs:\", y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c161fd1a",
   "metadata": {},
   "source": [
    "# Example 2: Simple CNN for Image Classification"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1c399c9c",
   "metadata": {},
   "source": [
    "Task: Classify black-and-white images into two categories (e.g., \"dark\" or \"light\" images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0eb0c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Generate Fake Image Data\n",
    "# We’ll simulate small 4x4 grayscale images with random values.\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ec46ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate fake image data (4x4 grayscale images)\n",
    "# 100 grayscale images (4x4 pixels, 1 channel)\n",
    "X_train = np.random.rand(100, 4, 4, 1) \n",
    "y_train = np.random.randint(0, 2, 100)  # Binary labels (0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e224bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.36340041],\n",
       "         [0.73711402],\n",
       "         [0.68923404],\n",
       "         [0.15374245]],\n",
       "\n",
       "        [[0.77360537],\n",
       "         [0.65242885],\n",
       "         [0.9953519 ],\n",
       "         [0.43209312]],\n",
       "\n",
       "        [[0.07121797],\n",
       "         [0.15293918],\n",
       "         [0.756096  ],\n",
       "         [0.91856765]],\n",
       "\n",
       "        [[0.14786036],\n",
       "         [0.92057175],\n",
       "         [0.42715404],\n",
       "         [0.19494318]]],\n",
       "\n",
       "\n",
       "       [[[0.17628069],\n",
       "         [0.41175562],\n",
       "         [0.56657345],\n",
       "         [0.24400793]],\n",
       "\n",
       "        [[0.34308725],\n",
       "         [0.67547991],\n",
       "         [0.77172331],\n",
       "         [0.20980291]],\n",
       "\n",
       "        [[0.91250415],\n",
       "         [0.50953185],\n",
       "         [0.31640869],\n",
       "         [0.10249556]],\n",
       "\n",
       "        [[0.09455419],\n",
       "         [0.64569152],\n",
       "         [0.97990587],\n",
       "         [0.39036188]]],\n",
       "\n",
       "\n",
       "       [[[0.14764532],\n",
       "         [0.41743549],\n",
       "         [0.79356519],\n",
       "         [0.98437196]],\n",
       "\n",
       "        [[0.53345984],\n",
       "         [0.84548349],\n",
       "         [0.56115566],\n",
       "         [0.42246287]],\n",
       "\n",
       "        [[0.5720855 ],\n",
       "         [0.12977479],\n",
       "         [0.82276033],\n",
       "         [0.68049246]],\n",
       "\n",
       "        [[0.64174691],\n",
       "         [0.10080593],\n",
       "         [0.86357827],\n",
       "         [0.76472105]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.69792596],\n",
       "         [0.41762174],\n",
       "         [0.46935157],\n",
       "         [0.79904441]],\n",
       "\n",
       "        [[0.12540487],\n",
       "         [0.93080329],\n",
       "         [0.84326426],\n",
       "         [0.80943335]],\n",
       "\n",
       "        [[0.09531062],\n",
       "         [0.17114225],\n",
       "         [0.71891764],\n",
       "         [0.93676989]],\n",
       "\n",
       "        [[0.05474767],\n",
       "         [0.0300923 ],\n",
       "         [0.33474414],\n",
       "         [0.3604839 ]]],\n",
       "\n",
       "\n",
       "       [[[0.46752233],\n",
       "         [0.90089105],\n",
       "         [0.55711003],\n",
       "         [0.52279023]],\n",
       "\n",
       "        [[0.29175422],\n",
       "         [0.42912184],\n",
       "         [0.48898395],\n",
       "         [0.30339424]],\n",
       "\n",
       "        [[0.07941201],\n",
       "         [0.98817213],\n",
       "         [0.25617184],\n",
       "         [0.54865997]],\n",
       "\n",
       "        [[0.67970812],\n",
       "         [0.43944727],\n",
       "         [0.16585414],\n",
       "         [0.32946084]]],\n",
       "\n",
       "\n",
       "       [[[0.00883969],\n",
       "         [0.80972108],\n",
       "         [0.26404067],\n",
       "         [0.00985468]],\n",
       "\n",
       "        [[0.64338787],\n",
       "         [0.43476584],\n",
       "         [0.63591798],\n",
       "         [0.86590285]],\n",
       "\n",
       "        [[0.21153072],\n",
       "         [0.55655195],\n",
       "         [0.68911077],\n",
       "         [0.42379052]],\n",
       "\n",
       "        [[0.82057369],\n",
       "         [0.91325265],\n",
       "         [0.59395665],\n",
       "         [0.45482581]]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3c1aad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(4, kernel_size=(2, 2), activation='relu', \n",
    "           input_shape=(4, 4, 1)),  # Convolutional Layer\n",
    "    Flatten(),  # Flatten for Dense layers\n",
    "    Dense(1, activation='sigmoid')# Output layer for binary classification\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1669348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a63bda74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 4s 22ms/step - loss: 0.7090 - accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7076 - accuracy: 0.4900\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7060 - accuracy: 0.4800\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7044 - accuracy: 0.4700\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7034 - accuracy: 0.4800\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7025 - accuracy: 0.4800\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7019 - accuracy: 0.4900\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7013 - accuracy: 0.4900\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7009 - accuracy: 0.5100\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7000 - accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x26ce02f1990>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a015d4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 110ms/step\n",
      "Predicted class (0 or 1): [[0]]\n"
     ]
    }
   ],
   "source": [
    "# Test the model on a new fake image\n",
    "X_test = np.random.rand(1, 4, 4, 1)  # 1 new image\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Predicted class (0 or 1):\", (y_pred > 0.5).astype(int))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "64ad492b",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "Conv2D Layer: Detects simple patterns in the images (like edges or blobs).\n",
    "Flatten: Converts 2D image features into a 1D array for processing in dense layers.\n",
    "Output Layer: Uses sigmoid activation to classify the image into 0 or 1."
   ]
  },
  {
   "cell_type": "raw",
   "id": "b9b75d2b",
   "metadata": {},
   "source": [
    "Key Differences Between ANN and CNN\n",
    "\n",
    "ANN:\n",
    "Used for structured data (e.g., numbers, tabular data).\n",
    "Processes each input independently without spatial relationships.\n",
    "\n",
    "CNN:\n",
    "Designed for image data or spatial patterns.\n",
    "Detects local patterns (like edges in an image) through convolutional layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d90fca2",
   "metadata": {},
   "source": [
    "# Example: ANN for Non-Linear Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01e28ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We’ll train an ANN to predict a quadratic function:\n",
    "# y=x^2+2x+1\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d730686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Generate training data\n",
    "X_train = np.array([1, 2, 3, 4, 5], dtype=float).reshape(-1, 1)  # Input x values\n",
    "y_train = X_train**2 + 2*X_train + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a3e35c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define the ANN model\n",
    "model = Sequential([\n",
    "    Dense(10, input_dim=1, activation='relu'),  # Hidden layer with 10 neurons\n",
    "    Dense(1)                                    # Output layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1367a6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6b90629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x26ce25421d0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Train the model\n",
    "model.fit(X_train, y_train, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ba03942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 77ms/step\n",
      "Predicted outputs for x=6 and x=7: [[1.823723 ]\n",
      " [2.0872128]]\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Test the model\n",
    "X_test = np.array([6, 7], dtype=float).reshape(-1, 1)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Predicted outputs for x=6 and x=7:\", y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b3873c",
   "metadata": {},
   "source": [
    "# CNN for Real Images (MNIST Dataset)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "94208134",
   "metadata": {},
   "source": [
    "We’ll classify digits from the MNIST dataset (images of numbers 0–9). Each image is 28x28 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6835053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59b7ad12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 13s 1us/step\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load the MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a87a0c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2decd799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Preprocess the data\n",
    "X_train = X_train.reshape(-1, 28, 28, 1).astype('float32') / 255  # Normalize and reshape\n",
    "X_test = X_test.reshape(-1, 28, 28, 1).astype('float32') / 255    # Normalize and reshape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d83f4327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(16, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),  # Convolutional layer\n",
    "    Flatten(),                                                                # Flatten into 1D\n",
    "    Dense(10, activation='softmax')                                           # Output layer (10 classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0768ab53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy'\n",
    "              , metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ce2d0453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "938/938 [==============================] - 10s 8ms/step - loss: 0.2380 - accuracy: 0.9354\n",
      "Epoch 2/3\n",
      "938/938 [==============================] - 8s 8ms/step - loss: 0.0811 - accuracy: 0.9774\n",
      "Epoch 3/3\n",
      "938/938 [==============================] - 7s 8ms/step - loss: 0.0591 - accuracy: 0.9829\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x26ce35e6a90>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 5: Train the model\n",
    "model.fit(X_train, y_train, epochs=3, verbose=1, batch_size=64)\n",
    "# Train for 3 epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4c214485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9790999889373779\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "76a672bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000026CE35EBC40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 470ms/step\n",
      "Predicted digit: 7\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Test on a single image\n",
    "import numpy as np\n",
    "single_image = X_test[0].reshape(1, 28, 28, 1)  # Reshape one test image\n",
    "prediction = model.predict(single_image)\n",
    "print(\"Predicted digit:\", np.argmax(prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392fb4a6",
   "metadata": {},
   "source": [
    "# practice Questions "
   ]
  },
  {
   "cell_type": "raw",
   "id": "7d2deb58",
   "metadata": {},
   "source": [
    "# 1. Predict a Linear Function\n",
    "# Data: 𝑦=3𝑥+2\n",
    "# Task: Build a simple neural network to predict y for new x values like 𝑥=10 or x=15."
   ]
  },
  {
   "cell_type": "raw",
   "id": "c749511e",
   "metadata": {},
   "source": [
    "2. Predict a Quadratic Function\n",
    "data: y=x^2-4x+5\n",
    "Task: Train a neural network to approximate this non-linear relationship. Test it for x=6 and x=8"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b3efae45",
   "metadata": {},
   "source": [
    "3. Simple Binary Classification\n",
    "data inputs x=[1,2,3,4,5] labels y=[0,0,1,1,1]\n",
    "Task: Train a neural network to classify y as 0 or 1 based on x values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e618e05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
