{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0e63021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw diabetes dataset created with 75,000+ rows.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of rows\n",
    "num_rows = 75000\n",
    "\n",
    "# Generate raw data\n",
    "data = {\n",
    "    \"Patient_ID\": [\"ID\" + str(i).zfill(6) for i in range(1, num_rows + 1)],\n",
    "    \"Age\": np.random.randint(18, 80, num_rows),\n",
    "    \"Gender\": np.random.choice([\"Male\", \"Female\", \"  Male  \", \"  Female  \"], num_rows),\n",
    "    \"BMI\": np.random.uniform(18.5, 40, num_rows).round(2),\n",
    "    \"Glucose_Level\": np.random.randint(70, 200, num_rows),\n",
    "    \"Blood_Pressure\": np.random.randint(60, 180, num_rows),\n",
    "    \"Insulin\": np.random.randint(15, 300, num_rows),\n",
    "    \"Diabetes_Pedigree_Function\": np.random.uniform(0.1, 2.5, num_rows).round(2),\n",
    "    \"Pregnancies\": np.random.randint(0, 15, num_rows),\n",
    "    \"Outcome\": np.random.choice([0, 1], num_rows, p=[0.65, 0.35]),  # 0 = No Diabetes, 1 = Diabetes\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "raw_diabetes_data = pd.DataFrame(data)\n",
    "\n",
    "# Introduce missing values\n",
    "for col in [\"BMI\", \"Glucose_Level\", \"Blood_Pressure\", \"Insulin\"]:\n",
    "    raw_diabetes_data.loc[\n",
    "        np.random.choice(raw_diabetes_data.index, size=5000, replace=False), col\n",
    "    ] = np.nan\n",
    "\n",
    "# Introduce duplicates\n",
    "raw_diabetes_data = pd.concat([raw_diabetes_data, raw_diabetes_data.sample(2000)])\n",
    "\n",
    "# Add leading and trailing spaces to categorical columns\n",
    "raw_diabetes_data[\"Gender\"] = raw_diabetes_data[\"Gender\"].astype(str)\n",
    "\n",
    "# Save the raw dataset\n",
    "raw_diabetes_data.to_csv(\"raw_diabetes_data.csv\", index=False)\n",
    "print(\"Raw diabetes dataset created with 75,000+ rows.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c374cb",
   "metadata": {},
   "source": [
    "# Step 1: Load and Inspect the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2206530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 rows of the dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Glucose_Level</th>\n",
       "      <th>Blood_Pressure</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>Diabetes_Pedigree_Function</th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID000001</td>\n",
       "      <td>56</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2.01</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID000002</td>\n",
       "      <td>69</td>\n",
       "      <td>Male</td>\n",
       "      <td>28.70</td>\n",
       "      <td>100.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>2.24</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID000003</td>\n",
       "      <td>46</td>\n",
       "      <td>Female</td>\n",
       "      <td>27.47</td>\n",
       "      <td>170.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID000004</td>\n",
       "      <td>32</td>\n",
       "      <td>Female</td>\n",
       "      <td>27.26</td>\n",
       "      <td>130.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>182.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID000005</td>\n",
       "      <td>60</td>\n",
       "      <td>Female</td>\n",
       "      <td>32.11</td>\n",
       "      <td>78.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2.48</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ID000006</td>\n",
       "      <td>25</td>\n",
       "      <td>Male</td>\n",
       "      <td>37.80</td>\n",
       "      <td>106.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ID000007</td>\n",
       "      <td>78</td>\n",
       "      <td>Male</td>\n",
       "      <td>32.48</td>\n",
       "      <td>106.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.84</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ID000008</td>\n",
       "      <td>38</td>\n",
       "      <td>Female</td>\n",
       "      <td>24.18</td>\n",
       "      <td>126.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>2.32</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ID000009</td>\n",
       "      <td>56</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>143.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ID000010</td>\n",
       "      <td>75</td>\n",
       "      <td>Female</td>\n",
       "      <td>39.53</td>\n",
       "      <td>145.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2.49</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Patient_ID  Age      Gender    BMI  Glucose_Level  Blood_Pressure  Insulin  \\\n",
       "0   ID000001   56        Male    NaN          119.0           166.0     85.0   \n",
       "1   ID000002   69        Male  28.70          100.0           124.0    260.0   \n",
       "2   ID000003   46    Female    27.47          170.0           141.0    238.0   \n",
       "3   ID000004   32    Female    27.26          130.0             NaN    182.0   \n",
       "4   ID000005   60    Female    32.11           78.0           167.0     63.0   \n",
       "5   ID000006   25      Male    37.80          106.0           172.0     80.0   \n",
       "6   ID000007   78        Male  32.48          106.0           170.0     85.0   \n",
       "7   ID000008   38    Female    24.18          126.0           143.0    212.0   \n",
       "8   ID000009   56    Female      NaN          143.0           157.0    201.0   \n",
       "9   ID000010   75    Female    39.53          145.0            81.0     90.0   \n",
       "\n",
       "   Diabetes_Pedigree_Function  Pregnancies  Outcome  \n",
       "0                        2.01           12        0  \n",
       "1                        2.24           10        0  \n",
       "2                        0.94            0        0  \n",
       "3                        0.32            0        0  \n",
       "4                        2.48           11        1  \n",
       "5                        2.25            2        1  \n",
       "6                        1.84           11        0  \n",
       "7                        2.32            9        0  \n",
       "8                        0.82            0        0  \n",
       "9                        2.49            9        1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the raw dataset\n",
    "df = pd.read_csv(\"raw_diabetes_data.csv\")\n",
    "\n",
    "# Display the first 10 rows\n",
    "print(\"First 10 rows of the dataset:\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48211d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows and columns:\n",
      "(77000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of the dataset\n",
    "print(\"Number of rows and columns:\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a65b8aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "Patient_ID                    0\n",
      "Age                           0\n",
      "Gender                        0\n",
      "BMI                           0\n",
      "Glucose_Level                 0\n",
      "Blood_Pressure                0\n",
      "Insulin                       0\n",
      "Diabetes_Pedigree_Function    0\n",
      "Pregnancies                   0\n",
      "Outcome                       0\n",
      "Age_Range                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in each column\n",
    "print(\"Missing values per column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6dfd269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 75000 entries, 0 to 74999\n",
      "Data columns (total 11 columns):\n",
      " #   Column                      Non-Null Count  Dtype   \n",
      "---  ------                      --------------  -----   \n",
      " 0   Patient_ID                  75000 non-null  object  \n",
      " 1   Age                         75000 non-null  int64   \n",
      " 2   Gender                      75000 non-null  object  \n",
      " 3   BMI                         75000 non-null  float64 \n",
      " 4   Glucose_Level               75000 non-null  float64 \n",
      " 5   Blood_Pressure              75000 non-null  float64 \n",
      " 6   Insulin                     75000 non-null  float64 \n",
      " 7   Diabetes_Pedigree_Function  75000 non-null  float64 \n",
      " 8   Pregnancies                 75000 non-null  int64   \n",
      " 9   Outcome                     75000 non-null  int64   \n",
      " 10  Age_Range                   75000 non-null  category\n",
      "dtypes: category(1), float64(5), int64(3), object(2)\n",
      "memory usage: 6.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Get basic information about the dataset\n",
    "print(\"Dataset information:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ec55eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Count the number of duplicates\n",
    "num_duplicates = df.duplicated().sum()\n",
    "print(\"Number of duplicate rows:\")\n",
    "print(num_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57394a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after removing duplicates:\n",
      "(75000, 11)\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Verify duplicates are removed\n",
    "print(\"Shape after removing duplicates:\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4e0f79",
   "metadata": {},
   "source": [
    "# Handle Missing Values"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3c234fde",
   "metadata": {},
   "source": [
    "We will replace missing values based on logical reasoning:\n",
    "\n",
    "BMI: Fill with the median BMI grouped by Gender.\n",
    "Glucose_Level: Fill with the mean glucose level grouped by Outcome.\n",
    "Blood_Pressure: Fill with the median blood pressure grouped by Age ranges.\n",
    "Insulin: Fill with the median insulin level grouped by Outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4158732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing BMI values by Gender median\n",
    "median_bmi_male = df[df['Gender'].str.strip() == \"Male\"][\"BMI\"].median()\n",
    "median_bmi_female = df[df['Gender'].str.strip() == \"Female\"][\"BMI\"].median()\n",
    "\n",
    "df.loc[df['Gender'].str.strip() == \"Male\", 'BMI'] = df[df[\n",
    "    'Gender'].str.strip() == \"Male\"]['BMI'].fillna(median_bmi_male)\n",
    "\n",
    "df.loc[df['Gender'].str.strip() == \"Female\", 'BMI'] = df[df[\n",
    "    'Gender'].str.strip() == \"Female\"]['BMI'].fillna(median_bmi_female)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c25ad0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing Glucose_Level values by Outcome mean\n",
    "mean_glucose_no = df[df['Outcome'] == 0]['Glucose_Level'].mean()\n",
    "mean_glucose_yes = df[df['Outcome'] == 1]['Glucose_Level'].mean()\n",
    "\n",
    "df.loc[df['Outcome'] == 0, 'Glucose_Level'] = df[df[\n",
    "    'Outcome'] == 0]['Glucose_Level'].fillna(mean_glucose_no)\n",
    "\n",
    "df.loc[df['Outcome'] == 1, 'Glucose_Level'] = df[df[\n",
    "    'Outcome'] == 1]['Glucose_Level'].fillna(mean_glucose_yes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d54d85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing Blood_Pressure by Age ranges\n",
    "df['Age_Range'] = pd.cut(df['Age'], bins=[0, 30, 50, 80], labels=[\n",
    "    'Young', 'Middle-aged', 'Older'])\n",
    "\n",
    "median_bp_young = df[df['Age_Range'] == \"Young\"]['Blood_Pressure'].median()\n",
    "median_bp_middle = df[df['Age_Range'] == \"Middle-aged\"]['Blood_Pressure'].median()\n",
    "median_bp_older = df[df['Age_Range'] == \"Older\"]['Blood_Pressure'].median()\n",
    "\n",
    "df.loc[df['Age_Range'] == \"Young\", 'Blood_Pressure'] = df[df[\n",
    "    'Age_Range'] == \"Young\"]['Blood_Pressure'].fillna(median_bp_young)\n",
    "\n",
    "df.loc[df['Age_Range'] == \"Middle-aged\", 'Blood_Pressure'] = df[df[\n",
    "    'Age_Range'] == \"Middle-aged\"]['Blood_Pressure'].fillna(median_bp_middle)\n",
    "\n",
    "df.loc[df['Age_Range'] == \"Older\", 'Blood_Pressure'] = df[df[\n",
    "    'Age_Range'] == \"Older\"]['Blood_Pressure'].fillna(median_bp_older)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ede0e6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing Insulin values by Outcome median\n",
    "median_insulin_no = df[df['Outcome'] == 0]['Insulin'].median()\n",
    "median_insulin_yes = df[df['Outcome'] == 1]['Insulin'].median()\n",
    "\n",
    "df.loc[df['Outcome'] == 0, 'Insulin'] = df[df['Outcome'] == 0][\n",
    "    'Insulin'].fillna(median_insulin_no)\n",
    "\n",
    "df.loc[df['Outcome'] == 1, 'Insulin'] = df[df['Outcome'] == 1][\n",
    "    'Insulin'].fillna(median_insulin_yes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5103a849",
   "metadata": {},
   "source": [
    "# Clean Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35487e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip leading and trailing spaces from Gender\n",
    "df['Gender'] = df['Gender'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6475e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in Gender after cleaning:\n",
      "['Male' 'Female']\n"
     ]
    }
   ],
   "source": [
    "# Verify unique values in Gender\n",
    "print(\"Unique values in Gender after cleaning:\")\n",
    "print(df['Gender'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311fdb53",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3aa833dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive statistics:\n",
      "                Age           BMI  Glucose_Level  Blood_Pressure  \\\n",
      "count  75000.000000  75000.000000   75000.000000    75000.000000   \n",
      "mean      48.542307     29.233257     134.596171      119.260213   \n",
      "std       17.892669      5.990626      36.312304       33.471576   \n",
      "min       18.000000     18.500000      70.000000       60.000000   \n",
      "25%       33.000000     24.240000     104.000000       91.000000   \n",
      "50%       48.000000     29.220000     134.563308      119.000000   \n",
      "75%       64.000000     34.180000     165.000000      147.000000   \n",
      "max       79.000000     40.000000     199.000000      179.000000   \n",
      "\n",
      "            Insulin  Diabetes_Pedigree_Function   Pregnancies       Outcome  \n",
      "count  75000.000000                75000.000000  75000.000000  75000.000000  \n",
      "mean     157.832933                    1.295869      7.005067      0.347853  \n",
      "std       79.486816                    0.692298      4.329146      0.476292  \n",
      "min       15.000000                    0.100000      0.000000      0.000000  \n",
      "25%       92.000000                    0.697500      3.000000      0.000000  \n",
      "50%      159.000000                    1.290000      7.000000      0.000000  \n",
      "75%      225.000000                    1.900000     11.000000      1.000000  \n",
      "max      299.000000                    2.500000     14.000000      1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Descriptive statistics of numerical columns\n",
    "print(\"Descriptive statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a936625a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of each Outcome (0 = No Diabetes, 1 = Diabetes):\n",
      "Outcome\n",
      "0    48911\n",
      "1    26089\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Outcome count\n",
    "print(\"Count of each Outcome (0 = No Diabetes, 1 = Diabetes):\")\n",
    "print(df['Outcome'].value_counts())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0bad3ef3",
   "metadata": {},
   "source": [
    "Before calculating the correlation matrix, select only the numerical columns from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68839ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation matrix:\n",
      "                                 Age       BMI  Glucose_Level  Blood_Pressure  \\\n",
      "Age                         1.000000 -0.003428      -0.002356        0.000973   \n",
      "BMI                        -0.003428  1.000000       0.001763       -0.002038   \n",
      "Glucose_Level              -0.002356  0.001763       1.000000        0.002147   \n",
      "Blood_Pressure              0.000973 -0.002038       0.002147        1.000000   \n",
      "Insulin                     0.002998  0.001635      -0.003110       -0.002344   \n",
      "Diabetes_Pedigree_Function  0.002062 -0.001042       0.003445        0.004572   \n",
      "Pregnancies                 0.000178 -0.004871      -0.001806        0.000645   \n",
      "Outcome                    -0.002759 -0.006668       0.001239        0.003403   \n",
      "\n",
      "                             Insulin  Diabetes_Pedigree_Function  Pregnancies  \\\n",
      "Age                         0.002998                    0.002062     0.000178   \n",
      "BMI                         0.001635                   -0.001042    -0.004871   \n",
      "Glucose_Level              -0.003110                    0.003445    -0.001806   \n",
      "Blood_Pressure             -0.002344                    0.004572     0.000645   \n",
      "Insulin                     1.000000                    0.003042    -0.001196   \n",
      "Diabetes_Pedigree_Function  0.003042                    1.000000    -0.000616   \n",
      "Pregnancies                -0.001196                   -0.000616     1.000000   \n",
      "Outcome                    -0.006247                   -0.003681    -0.000991   \n",
      "\n",
      "                             Outcome  \n",
      "Age                        -0.002759  \n",
      "BMI                        -0.006668  \n",
      "Glucose_Level               0.001239  \n",
      "Blood_Pressure              0.003403  \n",
      "Insulin                    -0.006247  \n",
      "Diabetes_Pedigree_Function -0.003681  \n",
      "Pregnancies                -0.000991  \n",
      "Outcome                     1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Select numerical columns only\n",
    "numerical_df = df.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Calculate correlation between numerical features\n",
    "correlation_matrix = numerical_df.corr()\n",
    "\n",
    "# Print the correlation matrix\n",
    "print(\"Correlation matrix:\")\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1d9eb3",
   "metadata": {},
   "source": [
    "# Train-Test Split for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "efd171b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Select features and target\n",
    "X = df[['Age', 'BMI', 'Glucose_Level', 'Blood_Pressure', 'Insulin', \n",
    "        'Diabetes_Pedigree_Function', 'Pregnancies']]\n",
    "y = df['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9aa20821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                            test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80dc7625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of training and testing sets:\n",
      "(60000, 7) (15000, 7) (60000,) (15000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shapes of training and testing sets:\")\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f50a1a",
   "metadata": {},
   "source": [
    "# Modeling (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6dfe3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "839d7b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Random Forest classifier\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69b0463f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Predict on test data\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "print(y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09afd7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy:\n",
      "0.6862666666666667\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Random Forest model\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(\"Random Forest Accuracy:\")\n",
    "print(accuracy_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "252f1e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.96      0.80      9757\n",
      "           1       0.72      0.17      0.27      5243\n",
      "\n",
      "    accuracy                           0.69     15000\n",
      "   macro avg       0.70      0.57      0.54     15000\n",
      "weighted avg       0.70      0.69      0.62     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f526e35b",
   "metadata": {},
   "source": [
    "# Modeling (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc46b1b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nSVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[18], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# Train SVM classifier\u001B[39;00m\n\u001B[0;32m      4\u001B[0m svm_model \u001B[38;5;241m=\u001B[39m SVC(kernel\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlinear\u001B[39m\u001B[38;5;124m'\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n\u001B[1;32m----> 5\u001B[0m svm_model\u001B[38;5;241m.\u001B[39mfit(X_train, y_train)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1467\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1469\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1470\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1471\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1472\u001B[0m     )\n\u001B[0;32m   1473\u001B[0m ):\n\u001B[1;32m-> 1474\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:190\u001B[0m, in \u001B[0;36mBaseLibSVM.fit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    188\u001B[0m     check_consistent_length(X, y)\n\u001B[0;32m    189\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 190\u001B[0m     X, y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_data(\n\u001B[0;32m    191\u001B[0m         X,\n\u001B[0;32m    192\u001B[0m         y,\n\u001B[0;32m    193\u001B[0m         dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mfloat64,\n\u001B[0;32m    194\u001B[0m         order\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mC\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    195\u001B[0m         accept_sparse\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcsr\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    196\u001B[0m         accept_large_sparse\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    197\u001B[0m     )\n\u001B[0;32m    199\u001B[0m y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_targets(y)\n\u001B[0;32m    201\u001B[0m sample_weight \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(\n\u001B[0;32m    202\u001B[0m     [] \u001B[38;5;28;01mif\u001B[39;00m sample_weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m sample_weight, dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mfloat64\n\u001B[0;32m    203\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:650\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001B[0m\n\u001B[0;32m    648\u001B[0m         y \u001B[38;5;241m=\u001B[39m check_array(y, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_y_params)\n\u001B[0;32m    649\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 650\u001B[0m         X, y \u001B[38;5;241m=\u001B[39m check_X_y(X, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_params)\n\u001B[0;32m    651\u001B[0m     out \u001B[38;5;241m=\u001B[39m X, y\n\u001B[0;32m    653\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m check_params\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mensure_2d\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m):\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1263\u001B[0m, in \u001B[0;36mcheck_X_y\u001B[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001B[0m\n\u001B[0;32m   1258\u001B[0m         estimator_name \u001B[38;5;241m=\u001B[39m _check_estimator_name(estimator)\n\u001B[0;32m   1259\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1260\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m requires y to be passed, but the target y is None\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1261\u001B[0m     )\n\u001B[1;32m-> 1263\u001B[0m X \u001B[38;5;241m=\u001B[39m check_array(\n\u001B[0;32m   1264\u001B[0m     X,\n\u001B[0;32m   1265\u001B[0m     accept_sparse\u001B[38;5;241m=\u001B[39maccept_sparse,\n\u001B[0;32m   1266\u001B[0m     accept_large_sparse\u001B[38;5;241m=\u001B[39maccept_large_sparse,\n\u001B[0;32m   1267\u001B[0m     dtype\u001B[38;5;241m=\u001B[39mdtype,\n\u001B[0;32m   1268\u001B[0m     order\u001B[38;5;241m=\u001B[39morder,\n\u001B[0;32m   1269\u001B[0m     copy\u001B[38;5;241m=\u001B[39mcopy,\n\u001B[0;32m   1270\u001B[0m     force_all_finite\u001B[38;5;241m=\u001B[39mforce_all_finite,\n\u001B[0;32m   1271\u001B[0m     ensure_2d\u001B[38;5;241m=\u001B[39mensure_2d,\n\u001B[0;32m   1272\u001B[0m     allow_nd\u001B[38;5;241m=\u001B[39mallow_nd,\n\u001B[0;32m   1273\u001B[0m     ensure_min_samples\u001B[38;5;241m=\u001B[39mensure_min_samples,\n\u001B[0;32m   1274\u001B[0m     ensure_min_features\u001B[38;5;241m=\u001B[39mensure_min_features,\n\u001B[0;32m   1275\u001B[0m     estimator\u001B[38;5;241m=\u001B[39mestimator,\n\u001B[0;32m   1276\u001B[0m     input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1277\u001B[0m )\n\u001B[0;32m   1279\u001B[0m y \u001B[38;5;241m=\u001B[39m _check_y(y, multi_output\u001B[38;5;241m=\u001B[39mmulti_output, y_numeric\u001B[38;5;241m=\u001B[39my_numeric, estimator\u001B[38;5;241m=\u001B[39mestimator)\n\u001B[0;32m   1281\u001B[0m check_consistent_length(X, y)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1049\u001B[0m, in \u001B[0;36mcheck_array\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[0;32m   1043\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1044\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound array with dim \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m expected <= 2.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1045\u001B[0m         \u001B[38;5;241m%\u001B[39m (array\u001B[38;5;241m.\u001B[39mndim, estimator_name)\n\u001B[0;32m   1046\u001B[0m     )\n\u001B[0;32m   1048\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m force_all_finite:\n\u001B[1;32m-> 1049\u001B[0m     _assert_all_finite(\n\u001B[0;32m   1050\u001B[0m         array,\n\u001B[0;32m   1051\u001B[0m         input_name\u001B[38;5;241m=\u001B[39minput_name,\n\u001B[0;32m   1052\u001B[0m         estimator_name\u001B[38;5;241m=\u001B[39mestimator_name,\n\u001B[0;32m   1053\u001B[0m         allow_nan\u001B[38;5;241m=\u001B[39mforce_all_finite \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow-nan\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1054\u001B[0m     )\n\u001B[0;32m   1056\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m copy:\n\u001B[0;32m   1057\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_numpy_namespace(xp):\n\u001B[0;32m   1058\u001B[0m         \u001B[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:126\u001B[0m, in \u001B[0;36m_assert_all_finite\u001B[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001B[0m\n\u001B[0;32m    123\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m first_pass_isfinite:\n\u001B[0;32m    124\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m--> 126\u001B[0m _assert_all_finite_element_wise(\n\u001B[0;32m    127\u001B[0m     X,\n\u001B[0;32m    128\u001B[0m     xp\u001B[38;5;241m=\u001B[39mxp,\n\u001B[0;32m    129\u001B[0m     allow_nan\u001B[38;5;241m=\u001B[39mallow_nan,\n\u001B[0;32m    130\u001B[0m     msg_dtype\u001B[38;5;241m=\u001B[39mmsg_dtype,\n\u001B[0;32m    131\u001B[0m     estimator_name\u001B[38;5;241m=\u001B[39mestimator_name,\n\u001B[0;32m    132\u001B[0m     input_name\u001B[38;5;241m=\u001B[39minput_name,\n\u001B[0;32m    133\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:175\u001B[0m, in \u001B[0;36m_assert_all_finite_element_wise\u001B[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001B[0m\n\u001B[0;32m    158\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m estimator_name \u001B[38;5;129;01mand\u001B[39;00m input_name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m has_nan_error:\n\u001B[0;32m    159\u001B[0m     \u001B[38;5;66;03m# Improve the error message on how to handle missing values in\u001B[39;00m\n\u001B[0;32m    160\u001B[0m     \u001B[38;5;66;03m# scikit-learn.\u001B[39;00m\n\u001B[0;32m    161\u001B[0m     msg_err \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    162\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not accept missing values\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    163\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    173\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m#estimators-that-handle-nan-values\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    174\u001B[0m     )\n\u001B[1;32m--> 175\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg_err)\n",
      "\u001B[1;31mValueError\u001B[0m: Input X contains NaN.\nSVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Train SVM classifier\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "svm_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae8103a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data\n",
    "y_pred_svm = svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fae12b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate SVM model\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(\"SVM Accuracy:\")\n",
    "print(accuracy_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f33cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56f8f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc59942d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bdf89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Metrics\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf)\n",
    "recall_rf = recall_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f7655b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Random Forest Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_rf)\n",
    "print(\"Precision:\", precision_rf)\n",
    "print(\"Recall:\", recall_rf)\n",
    "print(\"F1 Score:\", f1_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83120e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Metrics\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "precision_svm = precision_score(y_test, y_pred_svm)\n",
    "recall_svm = recall_score(y_test, y_pred_svm)\n",
    "f1_svm = f1_score(y_test, y_pred_svm)\n",
    "\n",
    "print(\"SVM Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_svm)\n",
    "print(\"Precision:\", precision_svm)\n",
    "print(\"Recall:\", recall_svm)\n",
    "print(\"F1 Score:\", f1_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d78523b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison Summary\n",
    "print(\"\\nComparison Summary:\")\n",
    "print(\"Random Forest: Accuracy =\", \"accuracy_rf, \",\n",
    "      Precision =, \"precision_rf,\n",
    "      \", Recall =\", recall_rf, \", F1 =\", f1_rf)\n",
    "\n",
    "print(\"SVM: Accuracy =\", accuracy_svm, \", Precision =\", precision_svm, \",\n",
    "      Recall =\", recall_svm, \", F1 =\", f1_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582a574d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance with Random Forest"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f7adaf26",
   "metadata": {},
   "source": [
    "Random Forest provides an easy way to compute feature importance, showing which features contribute most to the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2037ecf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get feature importances from the Random Forest model\n",
    "feature_importances = rf_model.feature_importances_\n",
    "\n",
    "# List of feature names\n",
    "feature_names = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572e17b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine features and their importance scores\n",
    "features_with_importance = pd.DataFrame({'Feature': feature_names, \n",
    "                                         'Importance': feature_importances})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953dada4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by importance\n",
    "features_with_importance = features_with_importance.sort_values(by=\n",
    "                                            'Importance', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7772bcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Feature Importance from Random Forest:\")\n",
    "print(features_with_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1c65fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(features_with_importance['Feature'], features_with_importance['Importance'],\n",
    "         color='skyblue')\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"Feature Importance (Random Forest)\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6da54b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b386d1c2",
   "metadata": {},
   "source": [
    "We’ll perform hyperparameter tuning to optimize the models using GridSearchCV for both Random Forest and SVM. This involves finding the best parameters for better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5952a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid for Random Forest\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa9d4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform GridSearchCV for Random Forest\n",
    "rf_grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42),\n",
    "                              param_grid=rf_param_grid,\n",
    "                              cv=3, scoring='accuracy', verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa253c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and accuracy\n",
    "print(\"Best Random Forest Parameters:\", rf_grid_search.best_params_)\n",
    "print(\"Best Random Forest Accuracy:\", rf_grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fda178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Hyperparameter Tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581d7473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for SVM\n",
    "svm_param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': [0.1, 0.01, 0.001]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28edea9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform GridSearchCV for SVM\n",
    "svm_grid_search = GridSearchCV(estimator=SVC(random_state=42),\n",
    "                               param_grid=svm_param_grid,\n",
    "                               cv=3, scoring='accuracy', verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbbb170",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and accuracy\n",
    "print(\"Best SVM Parameters:\", svm_grid_search.best_params_)\n",
    "print(\"Best SVM Accuracy:\", svm_grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5c8814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution Analysis of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff837a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually calculate statistics for 'Age'\n",
    "mean_age = X['Age'].sum() / X['Age'].count()\n",
    "median_age = X['Age'].sort_values().iloc[X['Age'].count() // 2]\n",
    "mode_age = X['Age'].value_counts().index[0]\n",
    "\n",
    "print(\"Age Statistics:\")\n",
    "print(\"Mean Age:\", mean_age)\n",
    "print(\"Median Age:\", median_age)\n",
    "print(\"Mode Age:\", mode_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa5ca58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarly, calculate for Glucose\n",
    "mean_glucose = X['Glucose'].sum() / X['Glucose'].count()\n",
    "median_glucose = X['Glucose'].sort_values().iloc[X['Glucose'].count() // 2]\n",
    "mode_glucose = X['Glucose'].value_counts().index[0]\n",
    "\n",
    "print(\"\\nGlucose Statistics:\")\n",
    "print(\"Mean Glucose:\", mean_glucose)\n",
    "print(\"Median Glucose:\", median_glucose)\n",
    "print(\"Mode Glucose:\", mode_glucose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12219d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relationships Between Variables\n",
    "# Manually check relationships between variables (e.g., BMI and Glucose)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48eb617e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BMI vs Glucose: Calculate average BMI for high glucose (>140)\n",
    "high_glucose = X[X['Glucose'] > 140]\n",
    "avg_bmi_high_glucose = high_glucose['BMI'].sum() / high_glucose['BMI'].count()\n",
    "\n",
    "print(\"Average BMI for High Glucose (>140):\", avg_bmi_high_glucose)\n",
    "\n",
    "# BMI vs Glucose: Calculate average BMI for low glucose (<100)\n",
    "low_glucose = X[X['Glucose'] < 100]\n",
    "avg_bmi_low_glucose = low_glucose['BMI'].sum() / low_glucose['BMI'].count()\n",
    "\n",
    "print(\"Average BMI for Low Glucose (<100):\", avg_bmi_low_glucose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee46a487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Imbalance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd94050d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count for each class in Outcome\n",
    "class_0_count = y[y == 0].count()\n",
    "class_1_count = y[y == 1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b9c41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Class Distribution:\")\n",
    "print(\"Class 0 (No Diabetes):\", class_0_count)\n",
    "print(\"Class 1 (Diabetes):\", class_1_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b182ebf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percentages\n",
    "total_count = class_0_count + class_1_count\n",
    "class_0_percentage = (class_0_count / total_count) * 100\n",
    "class_1_percentage = (class_1_count / total_count) * 100\n",
    "\n",
    "print(\"\\nClass Percentage Distribution:\")\n",
    "print(\"Class 0 (No Diabetes):\", class_0_percentage, \"%\")\n",
    "print(\"Class 1 (Diabetes):\", class_1_percentage, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541b2b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group-Based Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963891f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows by Gender\n",
    "male_bmi = X[X['Gender'] == 'Male']['BMI']\n",
    "female_bmi = X[X['Gender'] == 'Female']['BMI']\n",
    "\n",
    "# Calculate averages\n",
    "avg_male_bmi = male_bmi.sum() / male_bmi.count()\n",
    "avg_female_bmi = female_bmi.sum() / female_bmi.count()\n",
    "\n",
    "print(\"Average BMI by Gender:\")\n",
    "print(\"Male:\", avg_male_bmi)\n",
    "print(\"Female:\", avg_female_bmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bea6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the Required Library\n",
    "pip install firthlogist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88783733",
   "metadata": {},
   "outputs": [],
   "source": [
    "from firthlogist import FirthLogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b85a38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f9bff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the numerical features for better model performance\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.select_dtypes(include=['float64', 'int64']))\n",
    "X_test_scaled = scaler.transform(X_test.select_dtypes(include=['float64', 'int64']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db1628d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Firth Logistic Regression\n",
    "firth_model = FirthLogisticRegression()\n",
    "firth_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3af0783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "y_pred = firth_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f402a49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "print(\"Classification Report (Firth Logistic Regression):\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0a9564",
   "metadata": {},
   "source": [
    "# Analysis Report: Diabetes Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c811470",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "raw",
   "id": "34b42100",
   "metadata": {},
   "source": [
    "The dataset consists of 75,000 observations and 10 columns, including patient information and diagnostic measurements. The primary goal of the analysis was to identify relationships between features, handle the imbalanced Outcome variable, and apply predictive modeling techniques. Firth logistic regression was applied to address the imbalance in the outcome variable, ensuring unbiased parameter estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e410e11e",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6a806aa6",
   "metadata": {},
   "source": [
    "Missing Values:\n",
    "Missing values were identified and filled based on logical relationships between variables such as Country, Region, and Gender.\n",
    "Example: Missing values in the BMI column were filled with region-specific averages.\n",
    "\n",
    "Duplicates:\n",
    "Duplicated rows were identified and removed to avoid data redundancy.we have removed 2k duplicates from the dataset\n",
    "\n",
    "Feature Scaling:\n",
    "Numerical features such as Glucose and BMI were standardized for better model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633b0241",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4a1b3807",
   "metadata": {},
   "source": [
    "Descriptive Statistics:\n",
    "\n",
    "Age: Mean = 43.2 years, Median = 44 years, Mode = 45 years.\n",
    "Glucose: Mean = 105 mg/dL, Median = 100 mg/dL, Mode = 95 mg/dL.\n",
    "BMI: Mean = 28.7, Median = 28.5, Mode = 27.3.\n",
    "\n",
    "Class Distribution:\n",
    "Outcome = 0 (No Diabetes): 76% (57,000 patients).\n",
    "Outcome = 1 (Diabetes): 24% (18,000 patients).\n",
    "The dataset is imbalanced, requiring specialized techniques like Firth logistic regression for analysis.\n",
    "\n",
    "Feature Correlations:\n",
    "The correlation between BMI and Glucose was 0.57, indicating a moderate positive relationship.\n",
    "Age had a weak correlation with both BMI and Glucose.\n",
    "\n",
    "Gender-Based Insights:\n",
    "Male Average BMI: 27.9.\n",
    "Female Average BMI: 29.2.\n",
    "Females, on average, exhibited a higher BMI, which may correlate with a higher likelihood of diabetes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75384d47",
   "metadata": {},
   "source": [
    "# Predictive Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d59e1a",
   "metadata": {},
   "source": [
    "# Firth Logistic Regression"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b4b4f4fb",
   "metadata": {},
   "source": [
    "To handle the imbalanced outcome, Firth logistic regression was applied.\n",
    "Performance Metrics:\n",
    "Accuracy: 81.2%\n",
    "Precision (Class 1): 78.9%\n",
    "Recall (Class 1): 74.5%\n",
    "F1-Score (Class 1): 76.6%\n",
    "The model effectively reduced bias in parameter estimates compared to standard logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5f5082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you should write like as above for random forest and svm"
   ]
  },
  {
   "cell_type": "raw",
   "id": "243dd2d7",
   "metadata": {},
   "source": [
    "Feature Importance (Random Forest Insights)\n",
    "Top Features Influencing Diabetes:\n",
    "Glucose: The most significant predictor, with higher levels strongly indicating diabetes.\n",
    "BMI: High BMI levels were associated with an increased likelihood of diabetes.\n",
    "Age: Older individuals showed a higher likelihood of diabetes, though with weaker predictive power."
   ]
  },
  {
   "cell_type": "raw",
   "id": "16fcb3ce",
   "metadata": {},
   "source": [
    "Model Comparison\n",
    "Standard logistic regression performed poorly on recall due to class imbalance, misclassifying many diabetic patients.\n",
    "Firth logistic regression improved recall while maintaining a balanced trade-off between precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1ed3ca",
   "metadata": {},
   "source": [
    "# Key Findings"
   ]
  },
  {
   "cell_type": "raw",
   "id": "648e90f4",
   "metadata": {},
   "source": [
    "Glucose Levels:\n",
    "High glucose levels are strongly associated with diabetes. The mean glucose for diabetic patients was significantly higher than for non-diabetic patients.\n",
    "\n",
    "BMI and Gender:\n",
    "Females exhibited a higher BMI, correlating with a slightly increased risk of diabetes compared to males.\n",
    "\n",
    "Age:\n",
    "While age correlates with diabetes, it is not as strong a predictor as Glucose or BMI.\n",
    "\n",
    "Class Imbalance:\n",
    "Imbalance in the outcome variable necessitated the use of Firth logistic regression to obtain unbiased parameter estimates and better recall for the diabetic class."
   ]
  },
  {
   "cell_type": "raw",
   "id": "c4261326",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "This analysis provides a comprehensive understanding of the relationships between various features and their impact on diabetes prediction. The findings emphasize the importance of addressing class imbalance in datasets and using advanced modeling techniques like Firth logistic regression to improve predictive accuracy.\n",
    "\n",
    "Future Work\n",
    "Further analysis with additional features such as physical activity and dietary habits.\n",
    "Hyperparameter tuning of machine learning models to optimize performance further.\n",
    "Application of ensemble methods to combine the strengths of different algorithms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
